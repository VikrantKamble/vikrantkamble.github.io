---
layout: post
title:  "SQL Patterns"
date:   2024-03-29 00:18:23 +0700
categories: [sql]
usemathjax: true
---

**NOTE**: When solving *sql* questions always make sure that all the required components listed below are taken care of:

    SELECT {columns},
        AGG_FUNC {column(s)}
    FROM {table(s)}
    JOIN_TYPE {other_table(s)}
    ON {column_names}
    WHERE {conditions}
    GROUP BY {columns}
    HAVING {condition on aggregates}
    ORDER BY {column(s)}
    LIMIT {num rows} OFFSET {num}

---

Let's say we have a table called `Logins` that contains the following columns:

| Logins     |
|:-----------|
| user_id    |
| login_date |
| time_spent |

- What is the total time that each user spent for the month of Feb, 2024?
```sql
SELECT user_id, SUM(time_spent) AS total_time_spent
FROM Logins
WHERE DATE_FORMAT(login_date, '%Y-%m') = '2024-02'
GROUP BY 1;
```

- Which user(s) have logged in the most number of times for a given day?
```sql
WITH LoginsPerDay AS (
  SELECT user_id, login_date, COUNT(1) AS num_logins
  FROM Logins 
  GROUP BY 1, 2;
)
SELECT DISTINCT(user_id) AS user_id
FROM LoginsPerDay
WHERE num_logins = (SELECT MAX(num_logins) FROM LoginsPerDay)
```


- Which users have logged in for at least 5 consecutive days?
To answer this, we need to do a self-join where for any given row in the first table, we check
if there are rows in the second table that are within 5 days (including itself). Now there can be 
multiple logins on some day; hence we need to dedup using *DISTINCT*.
```sql
WITH LoginWindows AS (
  SELECT 
      l1.user_id,
      l1.login_date,
      COUNT(DISTINCT l2.login_date) AS logins_in_5_days
  FROM Logins l1
  JOIN Logins l2
    ON l1.user_id = l2.user_id
    AND l2.login_date BETWEEN l1.login_date AND DATE_ADD(l1.login_date, INTERVAL 4 DAY)
  GROUP BY l1.user_id, l1.login_date
)
SELECT DISTINCT user_id
FROM LoginWindows
WHERE logins_in_5_days = 5;
```

---

Let us now consider a table called `Friends` that contains the following columns:

| Friends    |
|:-----------|
| user1_id   |
| user2_id   |

Each row is ordered such that `user1_id` < `user2_id`.

- Calculate number of friends each user has?
Since a given row `(1, 2)` implies that both `user1_id` and `user2_id` have increased their friend 
count by 1; we need to somehow capture the information present in both these columns into a single 
column. We can do this using *UNION*.
```sql
WITH Connections AS (
    SELECT user1_id AS person FROM Friends
    UNION ALL
    SELECT user2_id FROM Friends
)
SELECT person, COUNT(1) AS num_friends
FROM Connections
GROUP BY 1
```

- Calculate number of mutual friends for each friend pair?
A mutual friend of a pair $A \leftrightarrow B$ is someone such that $A \leftrightarrow C$ and $C \leftrightarrow B$. Thus to find the mutual friends we need to do self-join twice. Since the given table 
only contains a directed edge $A \rightarrow B$, to create undirected edges we simply replicate the table 
swapping the user_id as follows:
```sql
    WITH Connections AS (
        SELECT user1_id, user2_id FROM Friends
        UNION
        SELECT user2_id, user1_id FROM Friends
    )
```

Now we can apply our *mutual friend* criteria. Note that the first table in the join is the *Friends* table and not the *Connections* table, to avoid double counting and maintain the ordering `user1_id` < `user2_id`.
```sql
SELECT c1.user1_id, c1.user2_id, COUNT(1) AS num_mutual_friends
FROM Friends c1, Connections c2, Connections c3
    WHERE c1.user1_id = c2.user1_id
    AND c2.user2_id = c3.user1_id
    AND c3.user2_id = c1.user2_id
GROUP BY 1, 2;
```

---

Let's consider a table `Visits` that contains entries for a particular month. 

| Visits       |
|:-------------|
| tenant_id    |
| pet_category |
| visit_date   |
| amount       |

Each entry (row) corresponds to a visit made by some tenant to supermarket to buy food for one of their pets along with the amount spent. 
Compute the total amount that each tenant spends on each *pet_category*, where *pet_category* is an **Enum** with values `cat, dog, fish`. The output should look like:

|   tenant_id |   cat |   dog |   fish |
|------------:|------:|------:|-------:|
|           1 |    20 |    40 |      0 |
|           2 |    34 |     0 |     25 |

We can get the total amount spent by each user per each pet category by simply doing a **groupby**. However, this will lead to a *long-format* table, 
which we will have to **pivot** to make the *wide-format* as required by the problem.

```sql
WITH ReqTable AS (
    SELECT tenant_id, pet_category, SUM(amount) AS total_amount
    FROM 
    GROUP BY 1, 2;
)
SELECT
    tenant_id,
    SUM(IF(pet_category = 'cat', total_amount, 0)) AS 'cat',
    SUM(IF(pet_category = 'dog', total_amount, 0)) AS 'dog',
    SUM(IF(pet_category = 'fish', total_amount, 0)) AS 'fish'
FROM ReqTable
GROUP BY 1;
```

---

The cancellation rate is computed by dividing the number of canceled (by client or driver) requests with unbanned users by the total number of requests with unbanned users on that day. Find the cancellation rate of unbanned users (both client and driver must not be banned) each day between "2013-10-01" and "2013-10-03". Round Cancellation Rate to two decimal points.

```sql
+-------------+----------+
| Column Name | Type     |
+-------------+----------+
| id          | int      |
| client_id   | int      |
| driver_id   | int      |
| city_id     | int      |
| status      | enum     |
| request_at  | date     |     
+-------------+----------+

+-------------+----------+
| Column Name | Type     |
+-------------+----------+
| users_id    | int      |
| banned      | enum     |
| role        | enum     |
+-------------+----------+
```

Since we only care about `unbanned` users we first check that neither `client_id` nor `driver_id` are banned.
```sql
SELECT 
    request_at AS Day,
    ROUND(AVG(IF(status = 'completed', 0, 1)), 2) AS `Cancellation Rate`
FROM Trips t
    WHERE client_id NOT IN (SELECT users_id FROM Users WHERE banned = 'Yes')
    AND driver_id NOT IN (SELECT users_id FROM Users WHERE banned = 'Yes')
    AND request_at BETWEEN '2013-10-01' AND '2013-10-03'
GROUP BY 1;
```

---
