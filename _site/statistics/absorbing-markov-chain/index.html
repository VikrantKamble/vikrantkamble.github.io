<!DOCTYPE html>
<!--
    So Simple Jekyll Theme 3.2.0
    Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
    Free for personal and commercial use under the MIT license
    https://github.com/mmistakes/so-simple-theme/blob/master/LICENSE
-->
<html lang="en-US" class="no-js">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  

  
    
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Absorbing Markov Chains | Stochastic Entity</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Absorbing Markov Chains" />
<meta name="author" content="Vikrant Kamble" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A Markov chain containing absorbing states is known as an absorbing Markov chain. So what is an absorbing state. In simple words, if you end up on an absorbing state you can’t go anywhere else; you are stuck there for all eternity. In other words, the probability of transition from an absorbing state $i$ to any other non-absorbing state, also called transient states, is 0." />
<meta property="og:description" content="A Markov chain containing absorbing states is known as an absorbing Markov chain. So what is an absorbing state. In simple words, if you end up on an absorbing state you can’t go anywhere else; you are stuck there for all eternity. In other words, the probability of transition from an absorbing state $i$ to any other non-absorbing state, also called transient states, is 0." />
<link rel="canonical" href="http://localhost:4000/statistics/absorbing-markov-chain/" />
<meta property="og:url" content="http://localhost:4000/statistics/absorbing-markov-chain/" />
<meta property="og:site_name" content="Stochastic Entity" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-12-13T09:23:00-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Absorbing Markov Chains" />
<meta name="twitter:site" content="@" />
<meta name="twitter:creator" content="@Vikrant Kamble" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Vikrant Kamble"},"dateModified":"2019-12-13T09:23:00-08:00","datePublished":"2019-12-13T09:23:00-08:00","description":"A Markov chain containing absorbing states is known as an absorbing Markov chain. So what is an absorbing state. In simple words, if you end up on an absorbing state you can’t go anywhere else; you are stuck there for all eternity. In other words, the probability of transition from an absorbing state $i$ to any other non-absorbing state, also called transient states, is 0.","headline":"Absorbing Markov Chains","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/absorbing-markov-chain/"},"url":"http://localhost:4000/statistics/absorbing-markov-chain/"}</script>
<!-- End Jekyll SEO tag -->


  

  <script>
    /* Cut the mustard */
    if ( 'querySelector' in document && 'addEventListener' in window ) {
      document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + 'js';
    }
  </script>

  <link rel="stylesheet" href="https://use.typekit.net/eio0pzn.css">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/skins/default.css">
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=EB+Garamond:400,400i,700,700i|Lora:400,400i,700,700i">
  <link rel="alternate" type="application/atom+xml" title="Stochastic Entity" href="/atom.xml">
<!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

</head>


  <body class="layout--post  absorbing-markov-chains">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#primary-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    
  <div class="navigation-wrapper">
    <a href="#menu-toggle" id="menu-toggle">Menu</a>
    <nav id="primary-nav" class="site-nav animated drop">
      <ul><li><a href="/posts">Home</a></li><li><a href="/categories/">Categories</a></li><li><a href="/tags/">Tags</a></li><li><a href="/search/">Search</a></li></ul>
    </nav>
  </div><!-- /.navigation-wrapper -->


    <header class="masthead">
  <div class="wrap">
    
    
    
      
        <div class="site-title animated fadeIn"><a href="/">Stochastic Entity</a></div>
      
      <p class="site-description animated fadeIn" itemprop="description">Personal blog for ideas and docs.</p>
    
  </div>
</header><!-- /.masthead -->


    <main id="main" class="main-content" aria-label="Content">
  <article class="h-entry">
    

    <div class="page-wrapper">
      <header class="page-header">
        
        
          <h1 id="page-title" class="page-title p-name">Absorbing Markov Chains
</h1>
        
      </header>

      <div class="page-sidebar">
        <div class="page-author h-card p-author"><img src="/images/headshot_compressed.jpg" class="author-avatar u-photo" alt="Vikrant Kamble"><div class="author-info"><div class="author-name">
        <em>by</em> <span class="p-name">Vikrant Kamble</span>
      </div><ul class="author-links"><li class="author-link">
            <a class="u-url" rel="me" href="https://instagram.com/vikrant10622"><i class="fab fa-instagram fa-lg" title="Instagram"></i></a>
          </li><li class="author-link">
            <a class="u-url" rel="me" href="https://github.com/VikrantKamble"><i class="fab fa-github-square fa-lg" title="GitHub"></i></a>
          </li></ul>
    <time class="page-date dt-published" datetime="2019-12-13T09:23:00-08:00"><a class="u-url" href="">December 13, 2019</a>
</time>

  </div>
</div>

        
  <h3 class="page-taxonomies-title">Categories</h3>
  
  <ul class="page-taxonomies"><li class="page-taxonomy">statistics</li>
  </ul>


        

      </div>

      <div class="page-content">
        <div class="e-content">
          <p>A Markov chain containing absorbing states is known as an absorbing Markov chain. So what is an absorbing state. In simple words, if you end up on an absorbing state you can’t go anywhere else; you are stuck there for all eternity. In other words, the probability of transition from an absorbing state $i$ to any other non-absorbing state, also called transient states, is 0.</p>

<p>At this point, we can make an observation:</p>

<blockquote>
0. The probability of eventually begin absorbed into any of the absorbing states given that one starts from anywhere is 1.
</blockquote>

<p>Let’s say we have $n$ transient states and $m$ absorbing states in the state space of any system. The transition matrix for such a system can be written as:</p>

<p>$$T = \left[ \begin{matrix} Q &amp; R \\ 0 &amp; I \end{matrix} \right],$$</p>

<p>where $Q$ of shape ($n \times n$) gives the probability of transitioning from transient state $i$ to transient state $j$. The matrix $R$ of shape $n \times m$ gives the probability of transitioning from transient state $i$ to absorbing state $j$, and $I$ of identity matrix of shape $m$.</p>

<p>We can compute the respective probability weights of the various states given a current probability weights by applying the transition matrix following the Markov property:</p>

\[v_{k+1} = T\ v_{k}\]

<p>Recursively expanding the above equation to the starting state $v_0$, we have</p>

\[v_{k} = T^k\ v_{0}\]

<p>It is interesting to compute what $T^k$ is:</p>

<p>
$$
\begin{align}
T^2 &amp;= \begin{bmatrix} Q &amp; R \\ 0 &amp; I \end{bmatrix} \begin{bmatrix} Q &amp; R \\ 0 &amp; I \end{bmatrix} = \begin{bmatrix} Q^2 &amp; QR + RI \\ 0 &amp; I \end{bmatrix} \\
T^3 &amp;= \begin{bmatrix} Q &amp; R \\ 0 &amp; I \end{bmatrix} \begin{bmatrix} Q^2 &amp; QR + RI \\ 0 &amp; I \end{bmatrix} = \begin{bmatrix} Q^3 &amp; Q^2R + QR + RI \\ 0 &amp; I \end{bmatrix}
\end{align}
$$
</p>

<p>Given the pattern we can write</p>

<p>$$T^k = \begin{bmatrix} Q^k &amp; R(I + Q + Q^2 + ... + Q^k) \\ 0 &amp; I \end{bmatrix}$$</p>

<p>Using the summation formula for a geometric sequence we can write:</p>

<p>$$ T^k = \begin{bmatrix} Q^k &amp; R \left(\frac{I - Q^k}{I - Q}\right) \\ 0 &amp; I \end{bmatrix} $$</p>

<p>From the above formula, we note that:</p>
<blockquote>
1. the probability the system is in transient state $j$ given that it started in transient state $i$ after $k$ steps is given by the $(i, j)^{th}$ entry of the matrix $Q^k$
</blockquote>

<p>The entries of $Q$ are all smaller than 1, given that these are probabilities. Hence we have $\lim_{k \to \infty} Q^k = 0$. This allows us to write</p>

<p>$$T^\infty = \begin{bmatrix} 0 &amp; R \left(\frac{1}{I - Q}\right) \\ 0 &amp; I \end{bmatrix} = \begin{bmatrix} 0 &amp; NR \\ 0 &amp; I \end{bmatrix},$$</p>

<p>where $N = [I - Q]^{-1}$ is known as the fundamental matrix. The $0’s$ in the first column of the above matrix proves statement given in blockquote 0.</p>

<p>From the above formula, we note that:</p>

<blockquote>
2. the probability the system ends up in absorbing state $j$ given that it started in transient state $i$ is the $(i, j)^{th}$ entry of the matrix $NR$.
</blockquote>

<p>The fundamental matrix $N$ has a very interesting interpretation:</p>
<blockquote>
3. its $(i, j)^{th}$ entry corresponds to the expected number of times the system visits transient state $j$ given that it started in transient state $i$, before being absorbed.
</blockquote>

<p>To see this, let us use a random indicator variable $\mathcal{I}_k$ which is 1 if the system is in state $j$ during $k^{th}$ step, else 0. The expected value of this indicator variable is:</p>

\[E[\mathcal{I}_k] = 1 \times prob(\mathcal{I}_k = 1) + 0 \times  prob(\mathcal{I}_k = 1) = Q^k_{i, j} \quad ......... \text{refer blockquote 1}\]

<p>The total number of visits we make to state $j$ in $n$ steps of the Markov chain is simply summing up all these indicator variables (one for each step).</p>

\[\text{total_visits after $n$ steps} = \mathcal{I}_0 + \mathcal{I}_1 + \mathcal{I}_2 + .....+\ \mathcal{I}_n\]

<p>Taking the expectation we get</p>

<p>
$$
\begin{align}
E[\text{total_visits after $n$ steps}] &amp;= E[\mathcal{I}_0] + E[\mathcal{I}_1] + E[\mathcal{I}_2] + .....+\ E[\mathcal{I}_n] \\
&amp;= Q^0_{i, j} +\ Q^1_{i, j} +\ ...+\ Q^n_{i, j}
\end{align}
$$
</p>

<p>Taking $n \to \infty$, we have
\(E[\text{total_visits}] = Q^0_{i, j} +\ Q^1_{i, j} +\ ...+\ Q^\infty_{i, j} = [I - Q]^{-1}_{i, j} = N_{i, j}\)</p>

<p>Summing this over all the possible transient states, we get the expected number of steps the Markov chain runs for, starting at state $i$, before getting absorbed into one of the absorbing states. This is nothing but adding the entries of the $i^{th}$ row of $N_{i, j}$:</p>

\[t_i = \sum_j N_{i, j}\]

<hr />

<p>Q1. <strong>On average, how many times do we have to roll a fair dice before seeing two 6’s in a row?</strong></p>

<p>Solution: One can represent the state space as $S = [6, E, 66]$, with $66$ being the absorbing state.</p>
<p align="center">
  <img src="/static/img/markov_66.png" width="400" />
</p>

<p>where $E = \{\phi, 1, 2, 3, 4, 5\}$. $\phi$ represents the null state $\to$ the state before we even began rolling the dice.</p>

<p>The transition matrix can be written as:</p>

<p>$$T = \begin{bmatrix} 0 &amp; 5/6 &amp; 1/6 \\ 1/6 &amp; 5/6 &amp; 0 \\ 0 &amp; 0 &amp; 1\end{bmatrix},$$</p>

<p>where the labels corresponds to the index as given in $S$. The fundamental matrix $N$ is given by:</p>

<p>
$$
\begin{align}
N = [I - Q]^{-1} &amp;= \left(\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix} - \begin{bmatrix} 0 &amp; 5/6 \\ 1/6 &amp; 5/6 \end{bmatrix}\right)^{-1}\\
   &amp;= \begin{bmatrix} 6 &amp; 30 \\ 6 &amp; 36 \end{bmatrix}
\end{align}
$$
</p>

<p>Since we begin in state $\phi$ which is at index $1$ (assuming 0 indexing), the average number of dice rolls before seeing two 6’s in a row is</p>

\[t_1 = N_{1,0} + N_{1, 1} = 42\]

<hr />

<p>Q2. <strong>You keep on tossing a fair coin until you see HHT or THT. Which of these combination is more likely to occur?</strong></p>

<p>The trick in most of such problems is to correctly identify the relevant state space. For this problem, the state space that we can use is
$S = [\phi, HH, HT, TH, TT, HHT, THT]$, where $HHT$ and $THT$ are the absorbing state. The transition diagram then becomes:</p>

<p align="center">
  <img src="/static/img/trans_diagram.png" width="400" />
</p>

<p>The red arrows indicates rolling a heads on the next roll, while blue arrows indicate rolling a tails on the next turn. Given this, the transition matrix becomes:</p>

<p align="center">
  <img src="/static/img/transition_mat.png" width="400" />
</p>
<!--
$$T = \begin{bmatrix} 0 & 1/4 & 1/4 & 1/4 & 1/4 & 0 & 0 \\
                      0 & 1/2 & 0 & 0 & 0 & 1/2 & 0 \\
                      0 & 0 & 0 & 1/2 & 1/2 & 0 & 0 \\
                      0 & 1/2 & 0 & 0 & 0 & 0 & 1/2 \\
                      0 & 0 & 0 & 1/2 & 1/2 & 0 & 0 \\
                      0 & 0 & 0 & 0 & 0 & 1 & 0 \\
                      0 & 0 & 0 & 0 & 0 & 0 & 1 \end{bmatrix},$$ -->

<p>where the labels corresponds to the index as given in $S$. The fundamental matrix then becomes:</p>

<p>
$$N = [I - Q]^{-1} = \begin{bmatrix} 1 &amp; 0 &amp; 0  &amp; 0 &amp; 0 \\
                      0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
                      0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
                      0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
                      0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\ \end{bmatrix},
$$
</p>

<p>where the $Q$ matrix is shown in green box. Following blockquote 2. the required matrix is given by:</p>

<p>$$P = NR = \begin{bmatrix} 5/8 &amp; 3/8 \\ 1 &amp; 0 \\ 1/2 &amp; 1/2 \\ 1/2 &amp; 1/2 \\1/2 &amp; 1/2 \end{bmatrix},$$</p>

<p>where $R$ is the matrix shown in blue. Thus the probability of starting from $\phi$ and ending up in the $HHT$ state is $5/8$, while ending up in the $THT$ state is $3/8$.</p>

<p>Q3. <strong>On average, how many times must a 6-sided die be rolled until all sides appear at least once? What about for an n-sided die?</strong></p>

<p>Let $n_i$ be the number of times face $i$ has shown up since we started rolling the dice. We now define an indicator variable $\mathcal{I}_i = \mathcal{I} (n_i &gt; 0)$ and a random variable $X$ that is the sum of these indicator variables $\mathcal{I}_1$ to $\mathcal{I}_6$. The possible values of $X$ serves as the states of the system, i.e. $S = [1, 2, 3, 4, 5, 6]$.</p>

<p>The state $X=6$ can then be identified as the absorbing state, which happens when we see all the faces of the dice. The state diagram is given as:</p>

<p align="center">
  <img src="/static/img/dice_face.png" width="400" />
</p>

<p>The transition matrix corresponding to this can be written as:</p>

<p>
$$T = \begin{bmatrix}
                      1/6 &amp; 5/6 &amp; 0 &amp; 0 &amp; 0 &amp;0 \\
                      0 &amp; 2/6 &amp; 4/6 &amp; 0 &amp; 0 &amp;0\\
                      0 &amp; 0 &amp; 3/6 &amp; 3/6 &amp; 0 &amp;0\\
                      0 &amp; 0 &amp; 0 &amp; 4/6 &amp; 2/6 &amp;0\\
                      0 &amp; 0 &amp; 0 &amp; 0 &amp; 5/6 &amp;1/6\\
                      0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix},$$
</p>

<p>where the labels corresponds to the index as given in $S$. The fundamental matrix is given by:</p>

<p>
$$N = [I - Q]^{-1} = \begin{bmatrix}
                      1.2 &amp; 1.5 &amp; 2 &amp; 3 &amp; 6 \\
                      0 &amp; 1.5 &amp; 2 &amp; 3 &amp; 6\\
                      0 &amp; 0 &amp; 2 &amp; 3 &amp; 6\\
                      0 &amp; 0 &amp; 0 &amp; 3 &amp; 6\\
                      0 &amp; 0 &amp; 0 &amp; 0 &amp; 6
\end{bmatrix}$$
</p>

<p>Since we begin in state $1$ (after one dice roll) which is at index $0$, the average number of dice rolls before seeing all sides appear is:</p>

\[t_{\phi} = 1 + \sum_{j} N_{0j} = 1 + (1.2 + 1.5 + 2 + 3 + 6) = 14.7\]

<p>The $1$ in the above equation is needed since initially we start with no dice roll (state $\phi$). The above summation can be written in an interesting way:</p>

\[t_{\phi} = 6\left(\frac{1}{6} + \frac{1}{5} + \frac{1}{4} + \frac{1}{3} + \frac{1}{2} + 1 \right)\]

<p>The quantity in the bracket is nothing but the $6^{th}$ <a href="https://en.wikipedia.org/wiki/Harmonic_number">Harmonic number</a> $H_6$. Hence generalizing to arbitrary sided dice, the expected number of rolls required before seeing all the faces of the $n-sided$ dice is:</p>

\[t_n = n\ H_n\]

<!-- <hr> -->

        </div>

        
          <div class="page-share">
  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fstatistics%2Fabsorbing-markov-chain%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--facebook btn--small"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i> <span>Share</span></a>
  <a href="https://twitter.com/intent/tweet?text=Absorbing+Markov+Chains%20http%3A%2F%2Flocalhost%3A4000%2Fstatistics%2Fabsorbing-markov-chain%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--twitter btn--small"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i> <span>Tweet</span></a>
  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fstatistics%2Fabsorbing-markov-chain%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--linkedin btn--small"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> <span>LinkedIn</span></a>
  <a href="https://reddit.com/submit?title=Absorbing+Markov+Chains&url=http%3A%2F%2Flocalhost%3A4000%2Fstatistics%2Fabsorbing-markov-chain%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--reddit btn--small"><i class="fab fa-fw fa-reddit" aria-hidden="true"></i> <span>Reddit</span></a>
</div>

        

        

        <nav class="page-pagination" role="navigation">
  
    <a class="page-previous" href="/statistics/logistic-regression/">
      <h4 class="page-pagination-label">Previous</h4>
      <span class="page-pagination-title">
        <i class="fas fa-arrow-left"></i> Logistic Regression

      </span>
    </a>
  

  
    <a class="page-next" href="/statistics/combinatorics/">
      <h4 class="page-pagination-label">Next</h4>
      <span class="page-pagination-title">
        Combinatorics, Tail sum for expectation and Simplices
 <i class="fas fa-arrow-right"></i>
      </span>
    </a>
  
</nav>

      </div>
    </div>
  </article>
</main>


    <footer id="footer" class="site-footer">
  <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
<div class="social-icons"><a class="social-icon" href="https://github.com/VikrantKamble"><i class="fab fa-github-square fa-2x" title="GitHub"></i></a></div><div class="copyright">
    
      <p>&copy; 2024 Stochastic Entity. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/mmistakes/so-simple-theme" rel="nofollow">So Simple</a>.</p>
    
  </div>
</footer>

    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>

<!-- for mathjax support --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      messageStyle: "none",
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  </body>

</html>
